{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "04e340d6-e35d-46c3-8cd0-2a6093c33568",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\BRU\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Loaded: (209527, 6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… Supervised Classification Results:\n",
      "Accuracy: 0.5734023767479597\n",
      "\n",
      "Classification Report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "          ARTS       0.34      0.16      0.21       293\n",
      "ARTS & CULTURE       0.32      0.11      0.16       275\n",
      "  BLACK VOICES       0.45      0.28      0.35       889\n",
      "      BUSINESS       0.47      0.44      0.45      1216\n",
      "       COLLEGE       0.42      0.29      0.35       202\n",
      "        COMEDY       0.53      0.38      0.44      1022\n",
      "         CRIME       0.51      0.51      0.51       713\n",
      "CULTURE & ARTS       0.57      0.22      0.32       202\n",
      "       DIVORCE       0.79      0.65      0.71       664\n",
      "     EDUCATION       0.46      0.28      0.35       209\n",
      " ENTERTAINMENT       0.52      0.74      0.61      3419\n",
      "   ENVIRONMENT       0.63      0.18      0.28       313\n",
      "         FIFTY       0.27      0.05      0.08       263\n",
      "  FOOD & DRINK       0.58      0.69      0.63      1270\n",
      "     GOOD NEWS       0.46      0.13      0.21       270\n",
      "         GREEN       0.37      0.28      0.32       532\n",
      "HEALTHY LIVING       0.38      0.21      0.27      1302\n",
      " HOME & LIVING       0.69      0.65      0.67       879\n",
      "        IMPACT       0.40      0.24      0.30       673\n",
      " LATINO VOICES       0.76      0.17      0.28       238\n",
      "         MEDIA       0.57      0.34      0.42       607\n",
      "         MONEY       0.53      0.32      0.40       355\n",
      "     PARENTING       0.50      0.66      0.57      1768\n",
      "       PARENTS       0.45      0.20      0.28       795\n",
      "      POLITICS       0.65      0.85      0.73      7155\n",
      "  QUEER VOICES       0.75      0.62      0.68      1262\n",
      "      RELIGION       0.62      0.40      0.48       530\n",
      "       SCIENCE       0.60      0.40      0.48       424\n",
      "        SPORTS       0.64      0.61      0.63      1014\n",
      "         STYLE       0.53      0.16      0.24       464\n",
      "STYLE & BEAUTY       0.70      0.78      0.74      1975\n",
      "         TASTE       0.34      0.08      0.13       427\n",
      "          TECH       0.51      0.36      0.42       398\n",
      " THE WORLDPOST       0.48      0.38      0.42       741\n",
      "        TRAVEL       0.63      0.76      0.69      2021\n",
      "     U.S. NEWS       0.47      0.05      0.09       269\n",
      "      WEDDINGS       0.75      0.70      0.72       709\n",
      "    WEIRD NEWS       0.36      0.21      0.26       550\n",
      "      WELLNESS       0.53      0.79      0.63      3672\n",
      "         WOMEN       0.44      0.29      0.35       727\n",
      "    WORLD NEWS       0.44      0.27      0.34       665\n",
      "     WORLDPOST       0.45      0.22      0.30       534\n",
      "\n",
      "      accuracy                           0.57     41906\n",
      "     macro avg       0.52      0.38      0.42     41906\n",
      "  weighted avg       0.56      0.57      0.55     41906\n",
      "\n",
      "âœ… Scraped 20 BBC articles\n",
      "                                                 url  \\\n",
      "0                        https://www.bbc.com/news/uk   \n",
      "1     https://www.bbc.com/news/articles/c207lj58p1qo   \n",
      "2  https://www.bbc.com/news/scotland/scotland_pol...   \n",
      "3     https://www.bbc.com/news/articles/c4glj74ey5qo   \n",
      "4     https://www.bbc.com/news/articles/cgqn5jjk55no   \n",
      "\n",
      "                                               title  \\\n",
      "0                                           NewsNews   \n",
      "1  Russian drone attacks cause massive power cuts...   \n",
      "2                                           NewsNews   \n",
      "3  Packed pub watches The Chase fan's posthumous win   \n",
      "4  Vast private zoo run by son of India's richest...   \n",
      "\n",
      "                                                text  cluster  \n",
      "0  year increase typical household twice analysts...        2  \n",
      "1  ukrainian homes left without power latest russ...        4  \n",
      "2  simpson announced move appeared press conferen...        2  \n",
      "3  dozens family friends teacher died weeks appea...        5  \n",
      "4  investigators india visit vast private zoo own...        4  \n",
      "\n",
      "ðŸ”® Prediction:\n",
      " {'category': 'BUSINESS', 'cluster': 4}\n"
     ]
    }
   ],
   "source": [
    "# ===============================\n",
    "# NEWS CLASSIFICATION & CLUSTERING\n",
    "# (Supervised + Unsupervised)\n",
    "# ===============================\n",
    "\n",
    "import os\n",
    "import re\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.cluster import KMeans\n",
    "import joblib\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "STOPWORDS = set(stopwords.words('english'))\n",
    "def clean_text(text):\n",
    "    text = str(text).lower()\n",
    "    text = re.sub(r\"[^a-zA-Z\\s]\", \"\", text)\n",
    "    text = \" \".join([w for w in text.split() if w not in STOPWORDS])\n",
    "    return text\n",
    "def train_supervised(json_path, text_col, label_col, out_dir=\"./artifacts\"):\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    df = pd.read_json(json_path, lines=True)\n",
    "    print(\"Dataset Loaded:\", df.shape)\n",
    "    if \"short_description\" in df.columns:\n",
    "        df[text_col] = (df[text_col].astype(str) + \" \" + df[\"short_description\"].astype(str))\n",
    "\n",
    "    df[text_col] = df[text_col].astype(str).apply(clean_text)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        df[text_col], df[label_col], test_size=0.2, random_state=42\n",
    "    )\n",
    "    vectorizer = TfidfVectorizer(max_features=5000)\n",
    "    X_train_vec = vectorizer.fit_transform(X_train)\n",
    "    X_test_vec = vectorizer.transform(X_test)\n",
    "    clf = LogisticRegression(max_iter=200)\n",
    "    clf.fit(X_train_vec, y_train)\n",
    "    y_pred = clf.predict(X_test_vec)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    print(\"\\n Supervised Classification Results:\")\n",
    "    print(\"Accuracy:\", acc)\n",
    "    print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "    joblib.dump(clf, os.path.join(out_dir, \"supervised_model.pkl\"))\n",
    "    joblib.dump(vectorizer, os.path.join(out_dir, \"tfidf.pkl\"))\n",
    "\n",
    "    return clf, vectorizer\n",
    "def scrape_bbc(max_articles=50):\n",
    "    base_url = \"https://www.bbc.com/news\"\n",
    "    r = requests.get(base_url)\n",
    "    soup = BeautifulSoup(r.text, \"lxml\")\n",
    "\n",
    "    links = [a[\"href\"] for a in soup.select(\"a\") if a.get(\"href\", \"\").startswith(\"/news\")]\n",
    "    links = list(set([\"https://www.bbc.com\" + l for l in links]))[:max_articles]\n",
    "\n",
    "    articles = []\n",
    "    for url in links:\n",
    "        try:\n",
    "            res = requests.get(url, timeout=5)\n",
    "            sp = BeautifulSoup(res.text, \"lxml\")\n",
    "            title = sp.find(\"h1\")\n",
    "            paras = sp.find_all(\"p\")\n",
    "            if not title or not paras:\n",
    "                continue\n",
    "            text = \" \".join([p.get_text() for p in paras])\n",
    "            articles.append({\"url\": url, \"title\": title.get_text(), \"text\": clean_text(text)})\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    df = pd.DataFrame(articles)\n",
    "    print(f\"âœ… Scraped {len(df)} BBC articles\")\n",
    "    return df\n",
    "def build_topic_clusters(df, out_dir=\"./artifacts\", n_clusters=8):\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    vectorizer = TfidfVectorizer(max_features=5000)\n",
    "    X = vectorizer.fit_transform(df[\"text\"])\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "    df[\"cluster\"] = kmeans.fit_predict(X)\n",
    "\n",
    "    joblib.dump(kmeans, os.path.join(out_dir, \"cluster_model.pkl\"))\n",
    "    joblib.dump(vectorizer, os.path.join(out_dir, \"cluster_tfidf.pkl\"))\n",
    "    df.to_csv(os.path.join(out_dir, \"bbc_clusters.csv\"), index=False)\n",
    "    return df\n",
    "def predict_both(text, out_dir=\"./artifacts\"):\n",
    "    text_clean = clean_text(text)\n",
    "    clf = joblib.load(os.path.join(out_dir, \"supervised_model.pkl\"))\n",
    "    tfidf = joblib.load(os.path.join(out_dir, \"tfidf.pkl\"))\n",
    "    vec = tfidf.transform([text_clean])\n",
    "    supervised_pred = clf.predict(vec)[0]\n",
    "    kmeans = joblib.load(os.path.join(out_dir, \"cluster_model.pkl\"))\n",
    "    tfidf2 = joblib.load(os.path.join(out_dir, \"cluster_tfidf.pkl\"))\n",
    "    vec2 = tfidf2.transform([text_clean])\n",
    "    cluster_pred = kmeans.predict(vec2)[0]\n",
    "\n",
    "    return {\"category\": supervised_pred, \"cluster\": int(cluster_pred)}\n",
    "if __name__ == \"__main__\":\n",
    "    clf, vec = train_supervised(\n",
    "        json_path=\"News_Category_Dataset_v3.json\",   # <-- UPDATED FILE NAME\n",
    "        text_col=\"headline\",\n",
    "        label_col=\"category\",\n",
    "        out_dir=\"./artifacts\"\n",
    "    )\n",
    "    df_bbc = scrape_bbc(max_articles=20)\n",
    "    clusters = build_topic_clusters(df_bbc, out_dir=\"./artifacts\", n_clusters=6)\n",
    "    print(clusters.head())\n",
    "    result = predict_both(\n",
    "        \"The finance minister announced a new tax policy impacting banks and traders.\",\n",
    "        out_dir=\"./artifacts\"\n",
    "    )\n",
    "    print(\"\\nPrediction:\\n\", result)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
